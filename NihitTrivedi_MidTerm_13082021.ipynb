{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np #importing various libraries from sklearn to be used in the program\n",
    "iris = datasets.load_iris() #imported the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "MT=pd.read_csv(\"seeds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Kernel.Length</th>\n",
       "      <th>Kernel.Width</th>\n",
       "      <th>Asymmetry.Coeff</th>\n",
       "      <th>Kernel.Groove</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Perimeter  Compactness  Kernel.Length  Kernel.Width  \\\n",
       "0  15.26      14.84       0.8710          5.763         3.312   \n",
       "1  14.88      14.57       0.8811          5.554         3.333   \n",
       "2  14.29      14.09       0.9050          5.291         3.337   \n",
       "3  13.84      13.94       0.8955          5.324         3.379   \n",
       "4  16.14      14.99       0.9034          5.658         3.562   \n",
       "\n",
       "   Asymmetry.Coeff  Kernel.Groove  Type  \n",
       "0            2.221          5.220     1  \n",
       "1            1.018          4.956     1  \n",
       "2            2.699          4.825     1  \n",
       "3            2.259          4.805     1  \n",
       "4            1.355          5.175     1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area               0\n",
       "Perimeter          0\n",
       "Compactness        0\n",
       "Kernel.Length      0\n",
       "Kernel.Width       0\n",
       "Asymmetry.Coeff    0\n",
       "Kernel.Groove      0\n",
       "Type               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MT.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199, 7), (199,))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = MT.drop('Type', axis=1) #data \n",
    "Y = MT['Type'] #label\n",
    "\n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159, 7), (40, 7), (159,), (40,))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split feature and label sets to train and data sets.\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 10)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "scaler.fit(X_train)\n",
    "scaler.fit(X_test)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\",max_depth=5)\n",
    "#tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train, Y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing set: 0.950\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on testing set: {:.3f}\".format(tree.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.29446813 0.         0.         0.018332   0.02730554 0.0792968\n",
      " 0.58059753]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importances:\\n{}\".format(tree.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=90, random_state=0)\n",
    "\n",
    "forest.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(X_train, Y_train)))\n",
    "\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.19129981 0.24314129 0.03570991 0.11723228 0.13734651 0.06388485\n",
      " 0.21138535]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importances:\\n{}\".format(forest.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.950\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbrt = GradientBoostingClassifier(random_state=0,learning_rate=0.1)\n",
    "\n",
    "gbrt.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, Y_train)))\n",
    "\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.40964439 0.03700145 0.00133308 0.00656728 0.02141326 0.0863449\n",
      " 0.43769563]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature importances:\\n{}\".format(gbrt.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9056603773584906"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, Y_train)\n",
    "gnb.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all parameters not specified are set to their defaults\n",
    "# default solver is incredibly slow thats why we change it\n",
    "# solver = 'lbfgs'\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9371069182389937\n"
     ]
    }
   ],
   "source": [
    "score = logisticRegr.score(X_train, Y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n"
     ]
    }
   ],
   "source": [
    "score = logisticRegr.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC on test set: 97.50\n",
      "Accuracy of SVC on training set: 94.97\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "print('Accuracy of SVC on test set: {:.2f}'.format(clf.score(X_test, Y_test) * 100))\n",
    "print('Accuracy of SVC on training set: {:.2f}'.format(clf.score(X_train, Y_train) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report #imporitng classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 182 candidates, totalling 364 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 364 out of 364 | elapsed:    2.6s finished\n",
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "#Python scikit-learn provides a Pipeline utility to help automate machine learning workflows.\n",
    "#Pipelines work by allowing for a linear sequence of data transforms to be chained together \n",
    "#culminating in a modeling process that can be evaluated.\n",
    "\n",
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "\n",
    "# Create param grid.\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['lbfgs','liblinear','sag','saga']},\n",
    "    {'classifier': [GaussianNB()]},\n",
    "    {'classifier': [GradientBoostingClassifier(random_state=0.1,learning_rate=200)],\n",
    "    'classifier__n_estimators':list(range(10,101,10))},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10))},\n",
    "    {'classifier' : [svm.SVC(C=0.1,gamma=1,kernel='rbf')]}] #feeding logistic regression, random forest, naive bayesian and support vector in the pipeline\n",
    "    \n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 2, verbose=True, n_jobs=-1) #cross validation\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, Y_train) #best classification on both train and test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 182 candidates, totalling 364 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 364 out of 364 | elapsed:    3.0s finished\n",
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.623776739188721, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf = clf.fit(X_train, Y_train) #best classification on both train and test data\n",
    "\n",
    "best_clf.best_estimator_.get_params()['classifier'] #identifying the best classifier which is coming out to be random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = best_clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy is 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy is',best_clf.score(X_test, Y_test)) #accuracy of the model which pipeline selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is the best classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 22 candidates, totalling 44 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    1.7s finished\n"
     ]
    }
   ],
   "source": [
    "#Python scikit-learn provides a Pipeline utility to help automate machine learning workflows.\n",
    "#Pipelines work by allowing for a linear sequence of data transforms to be chained together \n",
    "#culminating in a modeling process that can be evaluated.\n",
    "\n",
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "\n",
    "# Create param grid.\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier': [GaussianNB()]},\n",
    "    {'classifier': [GradientBoostingClassifier(random_state=0.1,learning_rate=200)],\n",
    "    'classifier__n_estimators':list(range(10,101,10))},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10))},\n",
    "    {'classifier' : [svm.SVC(C=0.1,gamma=1,kernel='rbf')]}] #feeding logistic regression, random forest, naive bayesian and support vector in the pipeline\n",
    "    \n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 2, verbose=True, n_jobs=-1) #cross validation\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, Y_train) #best classification on both train and test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 22 candidates, totalling 44 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, gamma=1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf = clf.fit(X_train, Y_train) #best classification on both train and test data\n",
    "\n",
    "best_clf.best_estimator_.get_params()['classifier'] #identifying the best classifier which is coming out to be random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = best_clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy is 0.975\n"
     ]
    }
   ],
   "source": [
    "print('Model accuracy is',best_clf.score(X_test, Y_test)) #accuracy of the model which pipeline selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC is the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
